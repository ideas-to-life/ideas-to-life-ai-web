---
title: "From ad-hoc prompts to a coherent learning system"
date: 2026-01-23
summary: "This week focused on stabilising workflows and reframing Weekly Learning as a synthesis layer, reducing drift while enabling multiple learning threads to coexist."
tags: ["process", "systems", "experimentation", "documentation"]
draft: false
---

### This week’s focus
Stabilising Ideas to Life as a coherent, repeatable system by clarifying prompt roles, enforcing structural constraints, and reframing Weekly Learning as a synthesis layer that can integrate multiple learning threads without collapsing them into a single narrative.

### What actually happened
- Canonicalised prompt instructions as repeatable workflows rather than one-off commands, particularly around Weekly Learning deployment.
- Corrected “create vs publish” semantics so Google Antigravity validates and publishes existing artefacts instead of generating new files.
- Standardised deployment paths for experiments (cards + detail pages) and cheat sheets (interactive HTML/JavaScript) under `public/`), and retrofitted earlier deployments to match.
- Introduced reusable templates derived from actual repository content, reinforcing the repo as the source of truth.
- Executed and validated the updated Weekly Learning deploy flow end to end, confirming it worked as intended.
- Designed and adopted a multi-step Weekly Learning pipeline: raw notes → reflection → synthesis → deploy.
- Introduced the concept of learning threads distinct from the Weekly Learning cadence, keeping Weekly Learning as a timeboxed synthesis.
- Updated runbooks and prompts to reflect stricter structure locks, merge rules, and synthesis mode expectations.

### Key trade-offs
- Accepting stricter structure and non-negotiable templates in exchange for reduced editorial drift and rework.
- Choosing synthesis over completeness in Weekly Learning to avoid poor UX when multiple deep learnings emerge in the same week.
- Keeping thread linking manual for now, trading automation for process validation and control.
- Prioritising static, lightweight artefacts over richer frameworks to preserve deployability and consistency.

### What changed in my thinking
- Weekly Learning is better treated as an integrator, not a container for all learning detail.
- Clear semantic contracts (“experiment vs artefact”, “thread vs week”) are foundational, not cosmetic.
- Process velocity comes primarily from constraint clarity, not additional tooling or optimisation.
- Documentation and prompts function as system components and deserve the same rigor as code.
- Shipping artefacts is the fastest way to validate patterns and surface real constraints.

### Key takeaways
- Canonical workflows outperform clever prompts when consistency matters.
- Strong structure locks reduce cognitive load and editorial churn.
- Synthesis requires explicit guardrails when multiple learning threads coexist.
- Single sources of truth prevent drift more effectively than coordination.
- Exploration, codification, and automation work best as a deliberate sequence.

### Looking ahead (optional)
- Add early semantic checks in prompts to catch “create vs publish” mismatches.
- Strengthen prompt support for multi-thread synthesis without altering card templates.
- Improve Markdown hygiene and validation for internal docs before reuse.
- Clarify context-sharing strategies to reduce cross-conversation friction.
- Decide branding placement earlier in new artefact patterns to avoid iterative noise.

### Related learning threads this week
- [Human–AI workflows](/learnings/threads/human-ai-workflows/)
- [From idea to live experiment](/learnings/threads/idea-to-live-experiment/)
- [Systems with contracts](/learnings/threads/system-with-contracts/)